{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c399feb-3198-45ac-a2da-a3a8e839dcfd",
   "metadata": {},
   "source": [
    "# RAG-SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3dc36-7c73-405d-87f0-29349d39364d",
   "metadata": {},
   "source": [
    "RAG (Retrieval-Augmented Generation) with SQL is a method used to combine natural language processing (NLP) models, like GPT, with structured query retrieval from databases using SQL (Structured Query Language). The goal is to leverage both the power of language models to understand and generate human-like text and the accuracy of SQL queries to retrieve data from structured sources, like relational databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad988a62-c467-4916-9397-8c9e1e913f1e",
   "metadata": {},
   "source": [
    "![DESCRIPTION](ragsql.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7548a88-e4e6-474e-ab90-968a2745bb3a",
   "metadata": {},
   "source": [
    "### Input the Question or Query:\n",
    "The process begins with the user asking a question or making a request in natural language. For example, the question might be:\n",
    "\n",
    "\"What is the total number of movies available in the table?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2a767-3547-40d3-80d6-3a1360d85e4a",
   "metadata": {},
   "source": [
    "### Preprocess the Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa6087-3146-436b-a5ec-be5b307210f8",
   "metadata": {},
   "source": [
    "In some implementations, the input may need preprocessing. This could involve Breaking down the question into smaller units (words or tokens)  Recognizing the key parts of the query, such as the “total number,” “movies available,” and “in the table.” Identifying what kind of SQL query is needed based on the user’s request.\n",
    "### Retrieve Schema Information from the Database\n",
    "Before generating the SQL query, the system needs to understand the structure of the database to know which tables and columns contain the relevant information.The language model (or another retrieval system) retrieves the schema of the database, including table names, column names, and relationships between them.\n",
    "For example, the model might need to know that the companies table has a sector column and a revenue column, and there’s a year column somewhere indicating the timeframe.\n",
    "###  Translate Natural Language into SQL Query\n",
    "The key step is converting the natural language question into an SQL query. A language model (e.g., GPT or similar) is used to Understand the user's intent. Generate the SQL query based on the natural language input and the schema retrieved from the database.\n",
    "For the earlier question, the model might generate an SQL query like this\n",
    "\n",
    "SELECT COUNT(`ID`)\n",
    "AS TotalMovies FROM telugumovies_dataset;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae68832-5b75-417a-bc29-8a9062a857a3",
   "metadata": {},
   "source": [
    "### Execute the SQL Query\n",
    "Once the SQL query is generated, it is executed against the database. The system sends the SQL command to the relational database where the data is stored.\n",
    "\n",
    "The database processes the query and returns the relevant results, such as the average revenue of companies in the tech sector over the last five years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c047ff-5d28-4279-bbf8-cbc9b3e41256",
   "metadata": {},
   "source": [
    "### Post-process the Results\n",
    "The results returned by the SQL query may require some post-processing to make them more human-readable.For example Formatting the data (e.g., rounding numbers or displaying results in a table) Adding contextual information (e.g., explaining what the result represents).For instance, if the query returns the total number of movies in the table, the system might phrase it as:\n",
    "\n",
    "“There are 1400 movies in the dataset.”\n",
    "### Generate the Final Response\n",
    "After retrieving the structured data, the final response is generated. The system uses the information retrieved from the SQL query to craft a complete, coherent response that answers the original question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014e789-49f9-476d-8885-3e26b16b8345",
   "metadata": {},
   "source": [
    "### Return the Response to the User\n",
    "The final step is delivering the response to the user, either in a conversational format (text) or a more structured format (table, graph, etc.).\n",
    "This fusion of NLP models and SQL allows for powerful, conversational-style data retrieval from structured databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d2d47-bd9e-45a3-a080-6046780ca98c",
   "metadata": {},
   "source": [
    "### Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8dc58f-9e9f-4c2c-896d-cdf89df76625",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-experimental openai pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35870ee0-c402-4571-8566-1caf51c33ec0",
   "metadata": {},
   "source": [
    "#### Langchain\n",
    "langchain is a framework designed for building applications that combine large language models (LLMs) with various external data sources. It is particularly useful for creating chains of interactions between language models and other systems such as APIs, databases, and document retrieval systems.\n",
    "#### langchain-experimental\n",
    "This package contains experimental features and components that are not part of the stable langchain release. These features might still be under development or testing but provide access to cutting-edge methods that can be useful for advanced use cases.\n",
    "#### openai\n",
    "The openai Python package is used to interact with OpenAI’s API, enabling you to use their language models (like GPT-3, GPT-4) for various tasks such as text generation, question-answering, summarization, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a0720-1d52-4b01-b87e-99d866c7d1f3",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0569cc6-e8a2-4b9b-8d4d-0c85cd8bc12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acad063-c747-43e6-a2b8-b7f72af35da2",
   "metadata": {},
   "source": [
    "\"SQLDatabase\" is a utility provided by langchain that allows you to connect and interact with SQL databases. It abstracts the process of connecting to the database, running SQL queries, and retrieving results. You can use this class to create a connection to a SQL database (e.g., MySQL, PostgreSQL, SQLite) and use it within langchain to retrieve data for natural language queries.\n",
    "\n",
    "The \"OpenAI\" class provides an interface to interact with OpenAI’s language models (e.g., GPT-3, GPT-4). It allows you to send prompts to OpenAI’s API and receive natural language responses.This is how you access OpenAI's LLMs to generate responses, complete tasks, or convert natural language input into structured formats like SQL.\n",
    "\n",
    "\"SQLDatabaseChain\" is part of the langchain-experimental package, which is focused on experimental features. This class allows you to create a chain that specifically interacts with SQL databases. It uses language models to generate SQL queries from natural language and retrieve relevant data from the database.It connects the language model with the SQL database and enables it to process natural language queries by converting them into SQL queries, executing them, and returning results in a conversational format.\n",
    "\n",
    "\"PromptTemplate\" is used to structure the prompts that will be sent to the language model. It allows you to define templates with placeholders and then fill in those placeholders dynamically when generating the prompt.You can create customizable prompts for tasks like converting a natural language request into a SQL query, summarizing text, or answering questions.\n",
    "\n",
    "\"HumanMessagePromptTemplate\" This class helps structure a prompt specifically for chat-based conversations. It supports the creation of prompts that resemble human messages and are used in chat-based interactions with LLMs.  You use this template to generate human-like input, which will be processed by the LLM in a conversational format.\n",
    "\n",
    "\"ChatOpenAI\" is specifically tailored for chat-based interactions using OpenAI’s models (like GPT). It facilitates a back-and-forth conversation with the model. It allows you to send multiple conversational turns (messages) to the OpenAI API and get responses in a structured conversation format.\n",
    "\n",
    "\"HumanMessage\" and \"SystemMessage\" are part of langchain's message structure, representing the different types of messages in a conversation. HumanMessage Represents a message sent by the user (i.e., human input).SystemMessage Represents a message from the system that guides the conversation (often used to set context for the LLM). These classes are useful for building conversational agents where multiple types of messages (from human and system) need to be processed in context by the LLM.\n",
    "\n",
    "These imports work together to create an application where, You can ask natural language questions, and the system will convert them into SQL queries using OpenAI’s language models. The converted SQL queries are executed on a connected SQL database (via SQLDatabaseChain), and the results are retrieved. The interaction can be conversational, where human and system messages guide the behavior and context of the language model using ChatOpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1726c-1998-4844-9446-d861d2417d78",
   "metadata": {},
   "source": [
    "### Initialize the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5784b8-6c91-4d0d-ac09-37a4caec1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f124b-4ab2-4dd5-b93e-89e7d19aa610",
   "metadata": {},
   "source": [
    "The API key is provided when you sign up for OpenAI's services and is required to access their language models (like GPT-3 or GPT-4). This key will be used later to interact with OpenAI’s language models through the ChatOpenAI class.\"temperature=0\" This controls the \"creativity\" or randomness of the language model. A value of 0 makes the model more deterministic (it will produce the same response for the same input).\"openai_api_key=OPENAI_API_KEY\" This passes the OpenAI API key to authenticate your requests when communicating with the language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedcd5ba-dbd2-48a0-b89c-6bcaa6150548",
   "metadata": {},
   "source": [
    "### DataBase Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca67e3b4-459c-475e-8435-7bb3298b2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'localhost'\n",
    "port = '3306'\n",
    "username = 'root'\n",
    "#password = ''\n",
    "database_schema = 'mydb'\n",
    "mysql_uri = f\"mysql+pymysql://{username}@{host}:{port}/{database_schema}\"\n",
    "#mysql_uri = f\"mysql+pymysql://{username:password}@{host}:{port}/{database_schema}\"\n",
    "db = SQLDatabase.from_uri(mysql_uri, include_tables=['telugumovies_dataset'],sample_rows_in_table_info=2)\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fcaaa8-536a-4765-ae67-6b4929a1656c",
   "metadata": {},
   "source": [
    "host = 'localhost': Specifies the server where the MySQL database is hosted. In this case, it's running on the local machine (localhost).).\n",
    "port = '3306': This is the default port number for MySQL.\n",
    "username = 'root': The username used to access the database. In this case, it's the root user.\n",
    "password = 'password': The password for the root user to access the database.\n",
    "database_schema = 'database_name': The name of the database schema you're connecting to.\n",
    "\n",
    "This creates an instance of SQLDatabase, which establishes a connection to the MySQL database using the previously constructed mysql_uri. \"mysql_uri\" is the URI containing the credentials and details to connect to the MySQL database.\"include_tables=['table_name']\" This specifies that only the table job_details should be included for interaction in the context of this language model and database connection. The model will focus on generating SQL queries and interacting with this specific table.\"sample_rows_in_table_info=2\" This option will fetch and display 2 sample rows of data from the job_details table to help the language model better understand the structure and content of the table. This is particularly useful when generating SQL queries.\n",
    "\n",
    "\"db_chain\" creates a SQLDatabaseChain, which is responsible for converting natural language queries into SQL queries, running them against the MySQL database, and retrieving results. The chain uses both the language model (llm) and the database connection (db).\"llm\" The language model (ChatOpenAI) that will interpret natural language inputs and generate the corresponding SQL queries. \"db\" The SQLDatabase instance that contains the MySQL connection and table information. \"verbose=True\" This enables detailed logging of the interactions, which will print out the generated SQL queries, execution steps, and results. It’s useful for debugging and understanding how the language model interacts with the database.The SQLDatabaseChain takes that generated SQL query and runs it against the MySQL database connected via the SQLDatabase instance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff97f077-1767-45a3-8c93-b7d0f3c0967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_db(query: str) -> str:\n",
    "    db_context = db_chain(query)\n",
    "    db_context = db_context['result'].strip()\n",
    "    return db_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54774d1c-26d1-4a57-b3b1-118e7d8354ea",
   "metadata": {},
   "source": [
    "#### Function Definition\n",
    "This function is defined to take a natural language query as input (in the form of a string) and return the result from the database.\"query: str\" This parameter accepts a natural language query in string format. For example, a query might be, \"What is the total number of movies available in the table?\". The function will return a string, which will contain the database result after processing.\n",
    "\n",
    "#### Sending Query to the Database Chain\n",
    "The db_chain is an instance of SQLDatabaseChain created earlier. It processes the natural language input (query) using an AI language model and converts it into an appropriate SQL query.\n",
    "The SQL query is then executed against the connected database.\n",
    "The result of that SQL query is returned as a dictionary (which includes additional metadata).\n",
    "\n",
    "#### Extracting and Cleaning the Result\n",
    "The result of the SQL query is stored in the db_context dictionary under the key 'result'. This contains the outcome of the query (e.g., the number of jobs or some specific data).\n",
    ".strip() method removes any unnecessary whitespace (like spaces or newlines) from the start and end of the string to ensure the result is clean and ready to be returned.\n",
    "#### Returning the Result\n",
    "After the query is processed, converted into SQL, executed, and the result is cleaned, it is sent back as the output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "327dbdc2-8bd7-4576-beb9-6d7653e6c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(query: str) -> str:\n",
    "    db_context = retrieve_from_db(query)\n",
    "    \n",
    "    system_message = \"\"\"You are a movie database expert specializing in Telugu cinema.\n",
    "        Your task is to answer users' questions by providing relevant information from a database of Telugu movies.\n",
    "        The database contains the following information for each movie:\n",
    "        - Name of the movie\n",
    "        - Year of release\n",
    "        - Certificate given by the censor board\n",
    "        - Movie genre\n",
    "        - A brief description or plot of the movie\n",
    "        - Duration in minutes\n",
    "        - IMDb Rating\n",
    "        - Number of people who rated the movie\n",
    "        \n",
    "        Example:\n",
    "        \n",
    "        Input:\n",
    "        Which Telugu movies released in 2021 have the highest IMDb ratings?\n",
    "        \n",
    "        Context:\n",
    "        The Telugu movies released in 2021 with the highest IMDb ratings are:\n",
    "        1. Movie A - IMDb Rating: 8.5\n",
    "        2. Movie B - IMDb Rating: 8.3\n",
    "        \n",
    "        Output:\n",
    "        The highest-rated Telugu movies released in 2021 are Movie A (IMDb Rating: 8.5) and Movie B (IMDb Rating: 8.3).\n",
    "        \"\"\"\n",
    "    \n",
    "    human_qry_template = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"Input:\n",
    "        {human_input}\n",
    "        \n",
    "        Context:\n",
    "        {db_context}\n",
    "        \n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "      SystemMessage(content=system_message),\n",
    "      human_qry_template.format(human_input=query, db_context=db_context)\n",
    "    ]\n",
    "    response = llm(messages).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d958f01-4740-4099-bc58-b892b774f120",
   "metadata": {},
   "source": [
    "This generate function is designed to take a natural language query (related to Telugu movies) as input, interact with a database to retrieve relevant information, and then use an AI language model to generate a human-readable response.\n",
    "\n",
    "The generate function processes a user's natural language query, fetches relevant data from the database, and then uses an AI language model to produce a well-structured, natural language response based on that data.\n",
    "#### Retrieve Data from Database\n",
    "db_context = retrieve_from_db(query) This calls the previously defined retrieve_from_db function, which takes the user's query, generates a SQL query, and retrieves relevant information from the database. The resulting data is stored in db_context.The query is processed by retrieve_from_db, and the corresponding result from the database is fetched and assigned to db_context.\n",
    "#### Define System Message\n",
    "This string defines the system message that provides instructions to the AI language model (LLM). It establishes the AI’s role and context for generating responses.\n",
    "The AI is instructed to act as a \"movie database expert specializing in Telugu cinema.\"\n",
    "The message explains the kind of data the database contains, such as movie names, release years, genres, IMDb ratings, etc.\n",
    "It also provides an example of how the AI should handle input (from the user) and the corresponding output.\n",
    "This helps guide the model to structure its response in a specific way (focusing on relevant information from the query).\n",
    "#### Create a Human Message Template\n",
    "This defines the template for the human message that will be passed to the language model (LLM) to format the user input and database result.{human_input}: This is where the user's natural language query (like \"Which Telugu movies released in 2021 have the highest IMDb ratings?\") will be inserted.\n",
    "{db_context}: This is where the database result (db_context) from the earlier SQL query will be inserted (e.g., \"1. Movie A - IMDb Rating: 8.5\").The template format structures the human message in three parts, \"Input\" The original question from the user.\"Context\" The result retrieved from the database, which provides relevant data.\"Output\" The expected answer, which the language model will generate.\n",
    "#### Create the Messages\n",
    "This creates the list of messages that will be passed to the AI language model (llm) for generating a response.\"SystemMessage(content=system_message)\" This is the first message, which provides the AI with the context (i.e., that it is acting as a movie database expert, as defined earlier).\n",
    "\"human_qry_template.format(human_input=query, db_context=db_context)\" This creates the human message by formatting the user's query and the retrieved database context into the template. The AI will use this to understand the user’s input and the relevant data from the database.\n",
    "Together, these two messages provide the necessary information for the AI to generate a coherent response.\n",
    "#### Generate and return the Response from LLM\n",
    "The llm(messages) call sends both the system and human messages to the OpenAI model.\n",
    "The model processes the query, the database context, and the system instructions to produce a natural language response that answers the user’s query.\n",
    ".content retrieves the actual response content generated by the model.After the AI processes the input and the database context, it generates a final output, which is returned as the response to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde753a5-a97b-47a3-95d1-26c7e1936a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many movies are there?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(`ID`) AS TotalMovies FROM telugumovies_dataset;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(1400,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThere are 1400 movies in the dataset.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 1400 movies in the dataset.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"How many movies are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9f749d1-2d4e-4a8d-84b7-c8edd87733f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many movies are there with Action Genre?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(`ID`) AS `Total_Action_Movies` FROM telugumovies_dataset WHERE `Genre` LIKE '%Action%'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(630,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThere are 630 movies with the Action genre.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 630 movies with the Action genre.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"How many movies are there with Action Genre?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fba1bf-699b-4324-aff5-22d028829d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many movies in year 2015?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(`Movie`) AS `TotalMovies2015` FROM telugumovies_dataset WHERE `Year` = '2015';\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(61,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mTotal number of movies in the year 2015 is 61.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the year 2015, there were a total of 61 Telugu movies released.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"How many movies in year 2015?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d84e5-2fd4-432e-a45b-09becab785a0",
   "metadata": {},
   "source": [
    "# IT will take the column names and values from the question\n",
    "# it will take use of OPEN AI models to prepare the query\n",
    "# it will ask the database with the prepared query\n",
    "# the response will also be converted back to the Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7903ff-0c56-4a62-b91e-4765818ef6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
